import os
import re
import base64
import json
import time
import uuid
from typing import Dict, List, Any, Tuple
from datetime import datetime
from pathlib import Path
import requests
from PIL import Image
from pdf2image import convert_from_path
from mistralai import Mistral, UserMessage
from io import BytesIO
from supabase import create_client, Client

class QCMExtractor:
    def __init__(self, api_key: str = None, supabase_url: str = None, supabase_key: str = None):
        """Initialise l'extracteur avec la cl√© API Mistral et les credentials Supabase"""
        # Configuration Mistral
        self.api_key = api_key or os.getenv("MISTRAL_API_KEY")
        if not self.api_key:
            raise ValueError("La cl√© API Mistral est requise")
        
        self.client = Mistral(api_key=self.api_key)
        
        # Configuration Supabase
        self.supabase_url = supabase_url or os.getenv("SUPABASE_URL")
        self.supabase_key = supabase_key or os.getenv("SUPABASE_KEY")
        if not self.supabase_url or not self.supabase_key:
            raise ValueError("Les credentials Supabase sont requis")
        
        self.supabase: Client = create_client(self.supabase_url, self.supabase_key)
        
        # Cr√©er la structure de dossiers
        self.base_dir = Path("qcm_extraction")
        self.temp_dir = self.base_dir / "temp"
        self.pdfs_dir = self.temp_dir / "pdfs"
        self.images_dir = self.temp_dir / "images"
        self.outputs_dir = self.temp_dir / "outputs"
        self.logs_dir = self.base_dir / "logs"
        
        # Cr√©er tous les dossiers n√©cessaires
        for dir_path in [self.temp_dir, self.pdfs_dir, self.images_dir, self.outputs_dir, self.logs_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
    
    def _call_api_with_retry(self, func, *args, max_retries=3, delay=2, **kwargs):
        """Appelle une fonction API avec retry en cas d'erreur"""
        for attempt in range(max_retries):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                if "rate limit exceeded" in str(e).lower() and attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è Rate limit atteint, attente de {delay} secondes...")
                    time.sleep(delay)
                    delay *= 2  # Augmenter le d√©lai √† chaque tentative
                else:
                    raise e
    
    def download_pdf(self, url: str) -> str:
        """T√©l√©charge un PDF depuis une URL"""
        response = requests.get(url)
        response.raise_for_status()
        
        # Cr√©er un dossier unique pour ce PDF
        pdf_name = Path(url).name
        pdf_stem = Path(url).stem
        pdf_dir = self.pdfs_dir / pdf_stem
        pdf_dir.mkdir(exist_ok=True)
        
        # Sauvegarder le PDF
        pdf_path = pdf_dir / pdf_name
        with open(pdf_path, "wb") as f:
            f.write(response.content)
            
        return str(pdf_path)
    
    def pdf_to_images(self, pdf_path: str) -> List[str]:
        """Convertit un PDF en images"""
        pdf_path = Path(pdf_path)
        pdf_stem = pdf_path.stem
        
        # Cr√©er un dossier pour les images de ce PDF
        output_dir = self.images_dir / pdf_stem
        output_dir.mkdir(exist_ok=True)
        
        # Convertir le PDF en images
        images = convert_from_path(str(pdf_path))
        
        # Sauvegarder les images
        image_paths = []
        for i, image in enumerate(images):
            image_path = output_dir / f"page_{i+1}.jpg"
            image.save(str(image_path), "JPEG")
            image_paths.append(str(image_path))
            
        return image_paths
    
    def save_metadata(self, metadata: Dict[str, Any], pdf_path: str) -> str:
        """Sauvegarde les m√©tadonn√©es dans un fichier JSON"""
        pdf_stem = Path(pdf_path).stem
        output_dir = self.outputs_dir / pdf_stem
        output_dir.mkdir(exist_ok=True)
        
        metadata_path = output_dir / "metadata.json"
        with open(metadata_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
            
        return str(metadata_path)
    
    def convert_pdf_to_markdown(self, pdf_path: str, original_url: str) -> str:
        """Convertit un PDF en Markdown en utilisant l'OCR Mistral"""
        try:
            print("üìù Conversion du PDF en Markdown...")
            
            # Utiliser l'URL originale pour l'API OCR
            document_input = {"type": "document_url", "document_url": original_url}
            
            # Appeler l'API OCR pour extraire le texte avec retry
            ocr_response = self._call_api_with_retry(
                self.client.ocr.process,
                model="mistral-ocr-latest",
                document=document_input,
                include_image_base64=False
            )
            
            # Extraire le texte de toutes les pages
            markdown_content = ""
            for i, page in enumerate(ocr_response.pages):
                markdown_content += f"# Page {i+1}\n\n"
                markdown_content += page.markdown + "\n\n"
            
            # Sauvegarder le Markdown
            pdf_stem = Path(pdf_path).stem
            output_dir = self.outputs_dir / pdf_stem
            output_dir.mkdir(exist_ok=True)
            
            markdown_path = output_dir / "content.md"
            with open(markdown_path, "w", encoding="utf-8") as f:
                f.write(markdown_content)
            
            print(f"üíæ Markdown sauvegard√©: {markdown_path}")
            return str(markdown_path)
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la conversion en Markdown: {str(e)}")
            return None

    def save_to_supabase(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Sauvegarde les m√©tadonn√©es dans Supabase"""
        try:
            print("üíæ Sauvegarde dans Supabase...")
            
            # Chercher l'ue_id correspondant dans la table 'ue'
            if metadata["ue"]:
                result = self.supabase.table("ue").select("id").eq("numero", metadata["ue"]).execute()
                if result.data:
                    ue_id = result.data[0]["id"]
                else:
                    print(f"‚ö†Ô∏è UE {metadata['ue']} non trouv√©e dans la table 'ue'")
                    return None
            else:
                print("‚ö†Ô∏è Impossible de d√©terminer l'UE")
                return None
            
            # Pr√©parer les donn√©es pour Supabase
            supabase_data = {
                "ue_id": ue_id,
                "type": metadata["type"],
                "annee": metadata["annee"],
                "uuid": str(uuid.uuid4())  # G√©n√©rer un UUID unique
            }
            
            # Ins√©rer dans Supabase dans la table 'qcm'
            result = self.supabase.table("qcm").insert(supabase_data).execute()
            
            print("‚úÖ Donn√©es sauvegard√©es dans Supabase")
            return result.data[0] if result.data else None
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la sauvegarde dans Supabase: {str(e)}")
            return None

    def extract_metadata_from_path(self, url):
        """Extrait les m√©tadonn√©es d'un PDF √† partir de son URL."""
        print("üîç Extraction des m√©tadonn√©es...")
        
        try:
            # T√©l√©charger le PDF
            pdf_path = self.download_pdf(url)
            print(f"üì• PDF t√©l√©charg√©: {pdf_path}")
            
            # Convertir le PDF en Markdown en utilisant l'URL originale
            markdown_path = self.convert_pdf_to_markdown(pdf_path, url)
            if not markdown_path:
                return None
            
            # Lire le contenu Markdown
            with open(markdown_path, "r", encoding="utf-8") as f:
                text = f.read()
            
            # Extraire les m√©tadonn√©es du nom de fichier
            filename = url.split('/')[-1]
            
            type_doc = "Unknown"
            annee = None
            ue = None
            
            # Utiliser l'IA pour extraire le type de document, l'ann√©e et l'UE
            prompt = f"""Tu es un agent sp√©cialis√© dans l'analyse de documents PDF de QCM et corrections.
            Voici un exemple de ce que je veux :
            - Pour un fichier 'ue3-correction-cb1-s40-21-22-48479.pdf', le type doit √™tre 'Concours Blanc N¬∞1'
            - Pour le texte 'SESSION 2021 / 2022', l'ann√©e doit √™tre '2021 / 2022'
            - Pour le texte 'UE2', l'UE doit √™tre 'UE2'
            
            Analyse le texte suivant et d√©termine :
            1. Le type de document (exactement 'Concours Blanc N¬∞1' si c'est une correction de concours blanc, ou 'Colle N¬∞1' si c'est une colle)
            2. L'ann√©e de la session (format: 'XXXX / XXXX')
            3. L'UE (format: 'UE1', 'UE2', etc.)
            
            Texte √† analyser :
            {text[:1000]}
            
            R√©ponds uniquement avec le format suivant, sans autre texte :
            TYPE: [type]
            ANNEE: [ann√©e]
            UE: [ue]"""
            
            messages = [UserMessage(content=prompt)]
            response = self._call_api_with_retry(
                self.client.chat.complete,
                model="mistral-small-latest",
                messages=messages,
                temperature=0.0
            )
            
            # Parser la r√©ponse de l'IA
            response_text = response.choices[0].message.content.strip()
            type_match = re.search(r'TYPE:\s*(.*)', response_text)
            annee_match = re.search(r'ANNEE:\s*(.*)', response_text)
            ue_match = re.search(r'UE:\s*(.*)', response_text)
            
            if type_match:
                type_doc = type_match.group(1).strip()
            if annee_match:
                annee = annee_match.group(1).strip()
            if ue_match:
                ue = ue_match.group(1).strip()

            metadata = {
                'filename': filename,
                'ue': ue,
                'type': type_doc,
                'annee': annee,
                'markdown_path': markdown_path,
                'url': url  # Ajouter l'URL originale
            }
            
            print(f"‚úÖ M√©tadonn√©es extraites: {metadata}")
            
            # Sauvegarder les m√©tadonn√©es localement
            metadata_path = self.save_metadata(metadata, pdf_path)
            print(f"üíæ M√©tadonn√©es sauvegard√©es localement: {metadata_path}")
            
            # Sauvegarder dans Supabase
            qcm_table_entry = self.save_to_supabase(metadata)
            if not qcm_table_entry:
                print("‚ö†Ô∏è √âchec de la sauvegarde des m√©tadonn√©es QCM dans Supabase")
                return metadata # Retourne les m√©tadonn√©es extraites m√™me si la sauvegarde Supabase √©choue pour le QCM
            
            # Ajouter l'ID du QCM cr√©√© aux m√©tadonn√©es qui seront retourn√©es
            if qcm_table_entry and isinstance(qcm_table_entry, dict) and 'id' in qcm_table_entry:
                metadata['qcm_db_id'] = qcm_table_entry['id']
            else:
                print("‚ö†Ô∏è L'ID du QCM sauvegard√© n'a pas pu √™tre ajout√© aux m√©tadonn√©es retourn√©es.")
                # On continue quand m√™me, qcm_id_for_processing sera utilis√© en interne

            # PAUSE pour √©viter le rate limiting de l'API
            # print("‚è∏Ô∏è Pause de 10 secondes avant l'extraction des questions pour √©viter le rate limiting...")
            # time.sleep(10) # Pause de 10 secondes - D√©plac√© avant chaque phase d'extraction majeure

            # Extraire et sauvegarder les questions et ensuite les propositions
            qcm_id_for_processing = qcm_table_entry.get('id')
            markdown_file_path = metadata.get('markdown_path') 

            if qcm_id_for_processing and markdown_file_path:
                try:
                    with open(markdown_file_path, "r", encoding="utf-8") as f:
                        markdown_content_for_processing = f.read()
                    
                    print("‚ñ∂Ô∏è Lancement de la Phase 1: Extraction des questions...")
                    # Pause avant la premi√®re s√©rie d'appels API pour les questions
                    print("‚è∏Ô∏è Pause de 5 secondes avant l'extraction des questions...")
                    time.sleep(5)
                    saved_questions_details = self._extract_and_save_questions_only(markdown_content_for_processing, qcm_id_for_processing)
                    
                    if saved_questions_details:
                        print(f"‚ÑπÔ∏è Phase 1 termin√©e. {len(saved_questions_details)} question(s) ont des d√©tails sauvegard√©s.")
                        print("‚ñ∂Ô∏è Lancement de la Phase 2: Extraction des propositions...")
                        # Pause avant la deuxi√®me s√©rie d'appels API pour les propositions
                        print("‚è∏Ô∏è Pause de 10 secondes avant l'extraction des propositions...")
                        time.sleep(10) 
                        self._extract_and_save_propositions(markdown_content_for_processing, qcm_id_for_processing, saved_questions_details)
                        print("üèÅ Phase 2 termin√©e.")
                    else:
                        print("‚ö†Ô∏è Aucune question n'a √©t√© sauvegard√©e en Phase 1, donc la Phase 2 (propositions) est ignor√©e.")

                except FileNotFoundError:
                    print(f"‚ö†Ô∏è Fichier Markdown non trouv√© √† {markdown_file_path}")
                except Exception as e:
                    # Log plus d√©taill√© de l'erreur
                    import traceback
                    print(f"üî• Erreur majeure lors du traitement des questions/propositions pour QCM ID {qcm_id_for_processing}: {str(e)}")
                    print(f"Traceback: {traceback.format_exc()}")
            else:
                missing_info = []
                if not qcm_id_for_processing: missing_info.append("qcm_id de la table qcm")
                if not markdown_file_path: missing_info.append("markdown_path des m√©tadonn√©es")
                print(f"‚ö†Ô∏è Impossible d'extraire les questions/propositions: {', '.join(missing_info)} manquant.")
            
            return metadata
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de l'extraction des m√©tadonn√©es: {str(e)}")
            return None

    def encode_image_to_base64(self, image_path: str, max_size: int = 1000) -> str:
        """Encode une image en Base64 avec redimensionnement si n√©cessaire"""
        with Image.open(image_path) as img:
            # Convertir en RGB si n√©cessaire
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # Calculer le ratio de redimensionnement
            width, height = img.size
            if width > max_size or height > max_size:
                ratio = min(max_size/width, max_size/height)
                new_size = (int(width * ratio), int(height * ratio))
                img = img.resize(new_size, Image.Resampling.LANCZOS)
            
            # Am√©liorer le contraste
            from PIL import ImageEnhance
            enhancer = ImageEnhance.Contrast(img)
            img = enhancer.enhance(1.5)
            
            # Sauvegarder en JPEG avec compression
            from io import BytesIO
            buffer = BytesIO()
            img.save(buffer, format="JPEG", quality=85, optimize=True)
            
            # Encoder en Base64
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    def extract_text_from_image(self, image_path: str) -> str:
        """Extract text from an image using Mistral API."""
        try:
            with open(image_path, "rb") as image_file:
                base64_image = base64.b64encode(image_file.read()).decode("utf-8")

            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "Please extract and describe all the text content from this image. Focus on mathematical formulas, chemical equations, and any other technical content."
                        },
                        {
                            "type": "image_url",
                            "image_url": f"data:image/jpeg;base64,{base64_image}"
                        }
                    ]
                }
            ]

            response = self.client.chat.complete(
                model="mistral-small-latest",
                messages=messages,
                temperature=0.0,
                max_tokens=1000
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"Error extracting text from image: {e}")
            return ""
    
    def extract_qcm_from_pdf(self, pdf_path: str) -> Tuple[Dict[str, Any], List[Dict[str, Any]]]:
        """Extrait les m√©tadonn√©es d'un PDF en utilisant l'OCR Mistral"""
        # Extraire les m√©tadonn√©es de base
        metadata = self.extract_metadata_from_path(pdf_path)
        
        # Convertir le PDF en images
        image_paths = self.pdf_to_images(pdf_path)
        if not image_paths:
            return metadata, []
            
        # Utiliser l'OCR Mistral sur la premi√®re page
        try:
            with open(image_paths[0], "rb") as image_file:
                base64_image = base64.b64encode(image_file.read()).decode("utf-8")

            ocr_response = self.client.ocr.process(
                model="mistral-ocr-latest",
                document={
                    "type": "image_url",
                    "image_url": f"data:image/jpeg;base64,{base64_image}"
                }
            )
            
            # Pour l'instant, on ne retourne que les m√©tadonn√©es
            return metadata, []
            
        except Exception as e:
            print(f"Error during OCR processing: {e}")
            return metadata, []

    def _extract_and_save_questions_only(self, markdown_text: str, qcm_id: int) -> List[Dict[str, Any]]:
        """Phase 1: Extrait UNIQUEMENT les questions du texte Markdown page par page,
        les sauvegarde dans Supabase, et retourne les d√©tails des questions sauvegard√©es."""
        print(f"üìù Phase 1: Extraction des questions uniquement pour QCM ID: {qcm_id}...")
        
        page_sections = []
        # Regex pour trouver les en-t√™tes comme "# Page 1\\n\\n"
        # La regex pr√©c√©dente ne fonctionne pas, on la remplace par une expression plus souple
        header_matches = list(re.finditer(r'^# Page \d+', markdown_text, flags=re.MULTILINE))

        if not header_matches:
            print("‚ö†Ô∏è Aucun en-t√™te de page standard ('# Page X') trouv√©. Traitement du document entier comme une seule section.")
            if markdown_text.strip():
                page_sections.append(markdown_text.strip())
        else:
            for i, match in enumerate(header_matches):
                start_content = match.end()
                end_content = header_matches[i+1].start() if (i + 1) < len(header_matches) else len(markdown_text)
                page_content = markdown_text[start_content:end_content].strip()
                if page_content:
                    page_sections.append(page_content)
                    
            print(f"üîé Trouv√© {len(header_matches)} en-t√™tes de page dans le document.")
        
        if not page_sections:
            print("‚ÑπÔ∏è Aucun contenu de page trouv√© apr√®s le d√©coupage du Markdown pour les questions.")
            return []

        print(f"üìÑ Document divis√© en {len(page_sections)} section(s) de page pour l'extraction des questions.")
        all_questions_from_all_pages_api_data = []

        for i, page_markdown_content in enumerate(page_sections):
            print(f"üìÑ Traitement section {i + 1}/{len(page_sections)} pour questions...")
            
            if not page_markdown_content.strip():
                print(f"    ‚è© Section de page {i + 1} vide, ignor√©e pour questions.")
                continue

            truncated_page_markdown = page_markdown_content[:25000]

            prompt = f"""Tu es un expert en analyse de QCM (Questionnaires √† Choix Multiples).
            √Ä partir du contenu Markdown d'une section de page d'un document QCM fourni ci-dessous, identifie et extrais chaque question.

            Pour chaque question, tu dois fournir :
            1. Le num√©ro de la question (par exemple, 1, 2, 3) tel qu'il appara√Æt sur la page.
            2. Le texte int√©gral de la question. Cela inclut toute phrase d'introduction ou contexte faisant partie de la question elle-m√™me.
               EXCLUS IMP√âRATIVEMENT : Les options √† choix multiples (A,B,C,D,E), les corrections, ou les justifications.

            Contenu Markdown de la section de page √† analyser :
            ---
            {truncated_page_markdown}
            ---

            Retourne les questions extraites sous la forme d'un objet JSON. Cet objet doit contenir une unique cl√© "questions",
            dont la valeur est une liste d'objets. Chaque objet dans la liste repr√©sente une question et doit avoir
            les cl√©s "numero" (un entier) et "contenu" (une cha√Æne de caract√®res pour le texte de la question).
            Si aucune question n'est trouv√©e sur cette section de page, la liste "questions" doit √™tre vide.

            Exemple de format de retour attendu :
            {{
              "questions": [
                {{"numero": 1, "contenu": "Quelle est la formule chimique de l'eau ?"}},
                {{"numero": 2, "contenu": "Concernant la photosynth√®se, laquelle des affirmations suivantes est correcte ?"}}
              ]
            }}
            """
            try:
                messages = [UserMessage(content=prompt)]
                response = self._call_api_with_retry(
                    self.client.chat.complete,
                    model="mistral-small-latest", 
                    messages=messages,
                    temperature=0.0,
                    response_format={"type": "json_object"}
                )
                
                if response.choices and response.choices[0].message and response.choices[0].message.content:
                    extracted_data_str = response.choices[0].message.content
                    try:
                        raw_page_data = json.loads(extracted_data_str)
                        page_questions_list = []
                        if isinstance(raw_page_data, dict):
                            page_questions_list = raw_page_data.get("questions", [])
                        elif isinstance(raw_page_data, list): 
                            page_questions_list = raw_page_data
                        
                        if not isinstance(page_questions_list, list):
                            print(f"    ‚ö†Ô∏è Format de questions inattendu pour section {i+1} (pas une liste). Re√ßu: {page_questions_list}")
                            continue
                        
                        # D√©ballage am√©lior√© de la liste des questions
                        actual_questions_for_page = []
                        if not page_questions_list: # G√®re une liste vide retourn√©e par .get("questions", []) ou par l'API
                            pass # actual_questions_for_page reste vide
                        elif len(page_questions_list) == 1 and \
                             isinstance(page_questions_list[0], dict) and \
                             "questions" in page_questions_list[0] and \
                             isinstance(page_questions_list[0]["questions"], list):
                            # Cas o√π l'API retourne: [{"questions": [q1, q2, ...]}]
                            actual_questions_for_page = page_questions_list[0]["questions"]
                            print(f"    ‚ÑπÔ∏è Liste de questions imbriqu√©e trouv√©e et d√©ball√©e ({len(actual_questions_for_page)} questions).")
                        else:
                            # Cas normal o√π page_questions_list est d√©j√† la liste de questions [q1, q2, ...]
                            # ou pourrait √™tre une liste d'items malform√©s, v√©rifi√©s plus tard.
                            actual_questions_for_page = page_questions_list
                        
                        if actual_questions_for_page:
                            print(f"    üëç {len(actual_questions_for_page)} question(s) √† traiter pour la section {i+1} (apr√®s d√©ballage si n√©cessaire).")
                            all_questions_from_all_pages_api_data.extend(actual_questions_for_page)
                        else:
                            # Couvre le cas o√π page_questions_list √©tait vide initialement, ou si actual_questions_for_page est rest√©e vide.
                            print(f"    ‚ÑπÔ∏è Aucune question trouv√©e ou valide sur la section {i+1} apr√®s traitement API.")
                            # ---- AJOUT DES LOGS ----
                            if 'extracted_data_str' in locals() and extracted_data_str:
                                print(f"    [DEBUG] Contenu brut de la r√©ponse API (questions) pour section {i+1} qui a men√© √† aucune question valide: {extracted_data_str}")
                            else:
                                print(f"    [DEBUG] Pas de contenu de r√©ponse API √† logger pour section {i+1}.")
                            print(f"""    [DEBUG] Contenu Markdown envoy√© √† Mistral pour la section {i+1} (qui n'a retourn√© aucune question valide):
---
{truncated_page_markdown}
---""")
                            # ---- FIN AJOUT DES LOGS ----
                    except json.JSONDecodeError as e_json:
                        print(f"    ‚ö†Ô∏è Erreur JSON pour section {i+1}: {e_json}. R√©ponse: {extracted_data_str}")
                        # ---- AJOUT DES LOGS (copie pour √™tre s√ªr en cas d'erreur JSON aussi) ----
                        if 'extracted_data_str' in locals() and extracted_data_str:
                            print(f"    [DEBUG] Contenu brut de la r√©ponse API (questions) pour section {i+1} (ERREUR JSON): {extracted_data_str}")
                        print(f"""    [DEBUG] Contenu Markdown envoy√© √† Mistral pour la section {i+1} (ERREUR JSON):
---
{truncated_page_markdown}
---""")
                        # ---- FIN AJOUT DES LOGS ----
                else:
                    print(f"    ‚ö†Ô∏è R√©ponse API invalide/contenu manquant pour section {i+1}.")
                    # ---- AJOUT DES LOGS ----
                    print(f"""    [DEBUG] Contenu Markdown envoy√© √† Mistral pour la section {i+1} (R√©ponse API invalide/contenu manquant):
---
{truncated_page_markdown}
---""")
                    # ---- FIN AJOUT DES LOGS ----
            except Exception as e_api: 
                print(f"    üî• Erreur API majeure pour section {i+1} (questions): {str(e_api)}")

            if i < len(page_sections) - 1:
                print(f"    ‚è∏Ô∏è Pause de 5s avant section suivante...")
                time.sleep(5)
        
        if not all_questions_from_all_pages_api_data:
            print("‚ÑπÔ∏è Aucune question trouv√©e dans le document apr√®s traitement de toutes les pages.")
            return []

        print(f"üìä Total de {len(all_questions_from_all_pages_api_data)} questions collect√©es (brutes API).")
        
        questions_to_insert_in_supabase = []
        for q_api_data in all_questions_from_all_pages_api_data:
            if not isinstance(q_api_data, dict) or "numero" not in q_api_data or "contenu" not in q_api_data:
                print(f"‚ö†Ô∏è Donn√©e de question API malform√©e ignor√©e: {q_api_data}")
                continue
            try:
                numero = int(q_api_data["numero"])
                contenu_text = str(q_api_data["contenu"])
                if not contenu_text.strip(): 
                    print(f"‚ö†Ô∏è Contenu de question vide pour num√©ro {numero} (API), ignor√©.")
                    continue
                
                questions_to_insert_in_supabase.append({
                    "qcm_id": qcm_id,
                    "numero": numero, 
                    "contenu": {"text": contenu_text}, 
                    "uuid": str(uuid.uuid4()) 
                })
            except (ValueError, TypeError) as e:
                print(f"‚ö†Ô∏è Erreur de type/valeur pour q API data {q_api_data}: {e}")
                continue

        saved_questions_details = []
        if questions_to_insert_in_supabase:
            print(f"üíæ Sauvegarde de {len(questions_to_insert_in_supabase)} questions format√©es dans Supabase...")
            try:
                result_q = self.supabase.table("questions").insert(questions_to_insert_in_supabase).execute()
                if result_q.data:
                    print(f"‚úÖ {len(result_q.data)} questions sauvegard√©es dans Supabase.")
                    for db_q_data in result_q.data:
                        saved_questions_details.append({
                            "db_uuid": db_q_data.get("uuid"),
                            "qcm_id": db_q_data.get("qcm_id"), 
                            "numero": db_q_data.get("numero")  
                        })
                    # Filtrer ceux o√π uuid, qcm_id, ou numero pourraient √™tre None
                    saved_questions_details = [
                        q for q in saved_questions_details 
                        if q.get("db_uuid") and q.get("qcm_id") is not None and q.get("numero") is not None
                    ]
                    if len(saved_questions_details) != len(result_q.data):
                        print(f"‚ö†Ô∏è Discordance dans les d√©tails des questions sauvegard√©es collect√©es ({len(saved_questions_details)} vs {len(result_q.data)}).")
                else:
                    print(f"‚ö†Ô∏è Aucune donn√©e retourn√©e par Supabase apr√®s tentative d\'insertion des questions.")
            except Exception as e_insert_q: 
                print(f"üî• Erreur lors de l\'insertion des questions dans Supabase: {str(e_insert_q)}")
        else:
            print("‚ÑπÔ∏è Aucune question valide √† sauvegarder apr√®s filtrage des donn√©es API.")
        
        return saved_questions_details

    def _extract_and_save_propositions(self, markdown_text: str, qcm_id: int, saved_questions_details: List[Dict[str, Any]]):
        """Phase 2: Extrait les propositions pour des questions d√©j√† sauvegard√©es et les ins√®re dans Supabase."""
        if not saved_questions_details:
            print("‚ÑπÔ∏è Phase 2 Propositions: Aucune question sauvegard√©e fournie, donc pas de propositions √† extraire.")
            return

        print(f"üìù Phase 2: Extraction des propositions pour {len(saved_questions_details)} questions du QCM ID: {qcm_id}...")

        # R√©cup√©rer les UUIDs actuels des questions directement depuis Supabase
        # C'est crucial car les UUIDs peuvent changer si nous r√©ex√©cutons le script
        try:
            print(f"üîç R√©cup√©ration des UUIDs des questions depuis Supabase pour le QCM ID: {qcm_id}...")
            result = self.supabase.table("questions").select("id", "uuid", "numero").eq("qcm_id", qcm_id).execute()
            
            if not result.data:
                print(f"‚ö†Ô∏è Aucune question trouv√©e dans Supabase pour le QCM ID: {qcm_id}")
                return
                
            # Cr√©ation du mappage par num√©ro en utilisant les donn√©es de Supabase
            question_map_by_numero = {}
            for q in result.data:
                if "numero" in q and "id" in q and q["numero"] is not None and q["id"] is not None:
                    question_map_by_numero[q["numero"]] = q["id"]
            
            question_id_list = [q["id"] for q in result.data if "id" in q and q["id"] is not None]
            
            print(f"üìå Nombre de questions mapp√©es par num√©ro depuis Supabase: {len(question_map_by_numero)}")
            print(f"üìå Num√©ros des questions en base de donn√©es: {sorted(question_map_by_numero.keys())}")
            
            if not question_map_by_numero:
                print("‚ö†Ô∏è Aucune question n'a pu √™tre mapp√©e par num√©ro depuis Supabase.")
                return
                
        except Exception as e:
            print(f"üî• Erreur lors de la r√©cup√©ration des IDs des questions depuis Supabase: {str(e)}")
            # Utiliser les donn√©es fournies en argument comme fallback
            question_map_by_numero = {q["numero"]: q["db_uuid"] for q in saved_questions_details if q.get("numero") is not None and q.get("db_uuid")}
            question_id_list = [q["db_uuid"] for q in saved_questions_details if q.get("db_uuid")]
            print(f"üìå Utilisation du mappage fourni en argument (fallback): {len(question_map_by_numero)} questions")

        original_num_count = len(saved_questions_details)
        mapped_num_count = len(question_map_by_numero)
        if mapped_num_count < original_num_count:
            print(f"‚ö†Ô∏è {original_num_count - mapped_num_count} question(s) sauvegard√©e(s) n'ont pas pu √™tre mapp√©es par num√©ro (numero/db_uuid manquant?).")

        page_sections = []
        header_matches = list(re.finditer(r'^# Page \d+', markdown_text, flags=re.MULTILINE))
        if not header_matches:
            if markdown_text.strip(): page_sections.append(markdown_text.strip())
        else:
            for i, match in enumerate(header_matches):
                start_content = match.end()
                end_content = header_matches[i+1].start() if (i + 1) < len(header_matches) else len(markdown_text)
                page_content = markdown_text[start_content:end_content].strip()
                if page_content: page_sections.append(page_content)

        if not page_sections:
            print("‚ÑπÔ∏è Aucun contenu de page trouv√© pour l'extraction des propositions.")
            return

        all_reponses_to_insert_in_supabase = []
        total_api_calls_for_propositions = 0

        for i, page_markdown_content in enumerate(page_sections):
            print(f"üìÑ Traitement section {i + 1}/{len(page_sections)} pour propositions...")
            if not page_markdown_content.strip():
                print(f"    ‚è© Section de page {i + 1} vide, ignor√©e pour propositions.")
                continue
            
            # Tronquer le contenu pour √©viter de d√©passer les limites de prompt de l'API
            truncated_page_markdown_props = page_markdown_content[:20000] 

            prompt_props = f"""Tu es un expert en analyse de QCM.
            √Ä partir du contenu Markdown d'UNE SEULE section de page de QCM ci-dessous:
            Identifie CHAQUE question pr√©sente sur CETTE page par son num√©ro.
            Pour CHAQUE question identifi√©e sur CETTE page, extrais ses propositions de r√©ponses (A, B, C, D, E).

            Contenu Markdown de la section de page √† analyser :
            ---
            {truncated_page_markdown_props}
            ---

            Retourne un objet JSON. Cet objet doit contenir une unique cl√© "questions_propositions",
            dont la valeur est une LISTE d'objets. Chaque objet dans la liste repr√©sente une question trouv√©e sur la page
            et doit avoir les cl√©s :
            - "numero_question_sur_page" (un entier, le num√©ro de la question tel qu'identifi√© sur la page)
            - "propositions" (un objet avec les cl√©s "A", "B", "C", "D", "E" pour le texte des propositions. Utilise null si une proposition est manquante).

            Si aucune question ou proposition n'est trouv√©e sur cette page, la liste "questions_propositions" doit √™tre vide.

            Exemple de format de retour attendu pour UNE page :
            {{
              "questions_propositions": [
                {{
                  "numero_question_sur_page": 1,
                  "propositions": {{"A": "Texte A1", "B": "Texte B1", "C": "Texte C1", "D": "Texte D1", "E": "Texte E1"}}
                }},
                {{
                  "numero_question_sur_page": 2,
                  "propositions": {{"A": "Texte A2", "B": "Texte B2", "C": null, "D": "Texte D2", "E": null}}
                }}
              ]
            }}
            """
            try:
                total_api_calls_for_propositions +=1
                messages_props = [UserMessage(content=prompt_props)]
                response_props = self._call_api_with_retry(
                    self.client.chat.complete,
                    model="mistral-small-latest",
                    messages=messages_props,
                    temperature=0.0,
                    response_format={"type": "json_object"}
                )

                if response_props.choices and response_props.choices[0].message and response_props.choices[0].message.content:
                    extracted_props_str = response_props.choices[0].message.content
                    try:
                        raw_page_props_data = json.loads(extracted_props_str)
                        
                        questions_propositions_on_page = []
                        if isinstance(raw_page_props_data, dict):
                             questions_propositions_on_page = raw_page_props_data.get("questions_propositions", [])
                        
                        if not isinstance(questions_propositions_on_page, list):
                            print(f"    ‚ö†Ô∏è Format de 'questions_propositions' inattendu (pas une liste) pour section {i+1}. Re√ßu: {questions_propositions_on_page}")
                            continue

                        if questions_propositions_on_page:
                            print(f"    üëç {len(questions_propositions_on_page)} ensemble(s) de propositions extraits de la section {i+1}.")
                            # Ajout du log pour voir les num√©ros des questions pour cette page
                            question_nums_on_page = [item.get("numero_question_sur_page") for item in questions_propositions_on_page if isinstance(item, dict) and "numero_question_sur_page" in item]
                            print(f"        üî¢ Num√©ros des questions identifi√©es sur cette page: {sorted(question_nums_on_page)}")
                            
                            for item in questions_propositions_on_page:
                                if not isinstance(item, dict) or "numero_question_sur_page" not in item or "propositions" not in item:
                                    print(f"        ‚ö†Ô∏è Item de propositions malform√© ignor√©: {item}")
                                    continue
                                
                                num_on_page = item.get("numero_question_sur_page")
                                props_dict = item.get("propositions")

                                if not isinstance(num_on_page, int) or not isinstance(props_dict, dict):
                                    print(f"        ‚ö†Ô∏è Type de num√©ro ou propositions invalide pour item: {item}")
                                    continue

                                question_db_uuid = question_map_by_numero.get(num_on_page)
                                if not question_db_uuid:
                                    # Ce log est important pour le d√©bogage
                                    print(f"        ‚ùì Le num√©ro de question {num_on_page} (extrait par l'API sur la page) n'a pas √©t√© trouv√© dans les questions initialement sauvegard√©es ou leur mappage. Propositions ignor√©es pour ce num√©ro.")
                                    continue

                                for lettre, texte_proposition in props_dict.items():
                                    if lettre in ["A", "B", "C", "D", "E"]:
                                        if texte_proposition is not None:
                                            cleaned_texte = str(texte_proposition).strip()
                                            if cleaned_texte:
                                                # V√©rifier que l'UUID de la question existe bien dans la liste des UUIDs collect√©s en phase 1
                                                if question_db_uuid in question_id_list:
                                                    all_reponses_to_insert_in_supabase.append({
                                                        "question_id": question_db_uuid,
                                                        "lettre": lettre,
                                                        "contenu": {"text": cleaned_texte},
                                                        "uuid": str(uuid.uuid4()),
                                                        "est_correcte": False, 
                                                        "latex": None 
                                                    })
                                                else:
                                                    print(f"        ‚ö†Ô∏è L'ID {question_db_uuid} pour la question {num_on_page} n'est pas dans la liste des IDs valides. Proposition {lettre} ignor√©e.")
                        else:
                            print(f"    ‚ÑπÔ∏è Aucune proposition trouv√©e sur la section {i+1} par l'API.")
                    except json.JSONDecodeError as e_json_props:
                        print(f"    ‚ö†Ô∏è Erreur JSON pour propositions section {i+1}: {e_json_props}. R√©ponse: {extracted_props_str}")
                else:
                    print(f"    ‚ö†Ô∏è R√©ponse API invalide/contenu manquant pour propositions section {i+1}.")
            except Exception as e_api_props:
                print(f"    üî• Erreur API majeure pour propositions section {i+1}: {str(e_api_props)}")
            
            if i < len(page_sections) - 1: 
                print(f"    ‚è∏Ô∏è Pause de 5s avant section suivante pour propositions...")
                time.sleep(5)
        
        print(f"üìû Total d'appels API pour propositions: {total_api_calls_for_propositions}")

        if all_reponses_to_insert_in_supabase:
            print(f"üíæ Sauvegarde de {len(all_reponses_to_insert_in_supabase)} propositions de r√©ponses (total) dans Supabase...")
            chunk_size = 50 # R√©duire la taille du chunk pour plus de s√©curit√©
            total_inserted_count = 0
            for i_chunk in range(0, len(all_reponses_to_insert_in_supabase), chunk_size):
                chunk = all_reponses_to_insert_in_supabase[i_chunk:i_chunk + chunk_size]
                try:
                    result_r = self.supabase.table("reponses").insert(chunk).execute()
                    if result_r.data:
                        total_inserted_count += len(result_r.data)
                    else:
                        print(f"    ‚ö†Ô∏è Aucune donn√©e retourn√©e pour un chunk de {len(chunk)} propositions, mais pas d'erreur explicite (possible ON CONFLICT DO NOTHING?).")
                except Exception as e_r_batch:
                    print(f"    üî• Erreur lors de l'insertion d'un chunk de propositions: {str(e_r_batch)}")
                    # Log du premier √©l√©ment du chunk probl√©matique pour aider au d√©bogage
                    if chunk:
                         print(f"        Premier √©l√©ment du chunk probl√©matique: {chunk[0]}")
            
            if total_inserted_count > 0:
                 print(f"‚úÖ {total_inserted_count} propositions de r√©ponses sauvegard√©es au total dans Supabase.")
            if total_inserted_count < len(all_reponses_to_insert_in_supabase):
                 print(f"‚ö†Ô∏è {len(all_reponses_to_insert_in_supabase) - total_inserted_count} propositions n'ont peut-√™tre pas √©t√© sauvegard√©es correctement.")
        else:
            print("‚ÑπÔ∏è Aucune proposition de r√©ponse valide √† sauvegarder apr√®s traitement de toutes les pages.")
            
    # --- Fin des m√©thodes refactor√©es ---